{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "def cnnConvolve(filterDim, numFilters, images, W, b,hparameters={'stride':1,'pad':0}):\n",
    "    numImages = images.shape[0]\n",
    "    imageDim = images.shape[1]\n",
    "    stride=hparameters['stride']#为图方便，默认为1\n",
    "    pad=hparameters['pad']\n",
    "    convDim = (imageDim - filterDim+2*pad)/stride + 1;\n",
    "    convolvedFeatures = np.zeros([convDim, convDim, numFilters, numImages])\n",
    "    for imageNum in range(numImages):\n",
    "        for filterNum in range(numFilters):\n",
    "            convolvedImage = np.zeros([convDim, convDim]);\n",
    "            for i in range(convDim):\n",
    "                for  j in range(convDim):\n",
    "                    temp_image=images[imageNum,:,:]\n",
    "                    temp_w=W[filterNum,:,:]\n",
    "                    temp_b=b[filterNum]\n",
    "                    v_start=i*stride\n",
    "                    h_start=j*stride\n",
    "                    temp_conved=sigmoid(np.sum(temp_image[v_start:v_start+filterDim,h_start:h_start+filterDim]*temp_w)+temp_b)\n",
    "                    convolvedImage[i,j]=temp_conved\n",
    "            convolvedFeatures[:,:,filterNum,imageNum]=convolvedImage\n",
    "    return convolvedFeatures\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0250474   0.97005431  0.62342126  0.50241613  0.60429297  0.77847394\n",
      "   0.26657881]\n",
      " [ 0.42159289  0.07168768  0.21582596  0.55523751  0.48502261  0.79102939\n",
      "   0.86027143]\n",
      " [ 0.07710751  0.79405592  0.72392503  0.80571809  0.75404376  0.83943331\n",
      "   0.06057553]\n",
      " [ 0.56217804  0.1586037   0.98625029  0.86830841  0.87228947  0.53453032\n",
      "   0.36730653]\n",
      " [ 0.26779377  0.95338038  0.28504647  0.47707524  0.08122326  0.83673518\n",
      "   0.24098224]\n",
      " [ 0.16235835  0.58776987  0.65749585  0.01402991  0.22285323  0.98945993\n",
      "   0.36116441]\n",
      " [ 0.08521121  0.2395229   0.92958391  0.45926697  0.3788354   0.76737554\n",
      "   0.34353656]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.72392503,  0.80571809,  0.75404376],\n",
       "       [ 0.98625029,  0.86830841,  0.87228947],\n",
       "       [ 0.28504647,  0.47707524,  0.08122326]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.random.rand(7,7)\n",
    "print(a)\n",
    "a[2:5,2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "魔数:2051, 图片数量: 60000张, 图片大小: 28*28\n",
      "已解析 10000张\n",
      "已解析 20000张\n",
      "已解析 30000张\n",
      "已解析 40000张\n",
      "已解析 50000张\n",
      "已解析 60000张\n",
      "魔数:2051, 图片数量: 10000张, 图片大小: 28*28\n",
      "已解析 10000张\n",
      "魔数:2049, 图片数量: 60000张\n",
      "已解析 10000张\n",
      "已解析 20000张\n",
      "已解析 30000张\n",
      "已解析 40000张\n",
      "已解析 50000张\n",
      "已解析 60000张\n",
      "魔数:2049, 图片数量: 10000张\n",
      "已解析 10000张\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练集文件\n",
    "train_images_idx3_ubyte_file = '../data/common/train-images-idx3-ubyte'\n",
    "# 训练集标签文件\n",
    "train_labels_idx1_ubyte_file = '../data/common/train-labels-idx1-ubyte'\n",
    "\n",
    "# 测试集文件\n",
    "test_images_idx3_ubyte_file = '../data/common/t10k-images-idx3-ubyte'\n",
    "# 测试集标签文件\n",
    "test_labels_idx1_ubyte_file = '../data/common/t10k-labels-idx1-ubyte'\n",
    "def decode_idx3_ubyte(idx3_ubyte_file):\n",
    "    \"\"\"\n",
    "    解析idx3文件的通用函数\n",
    "    :param idx3_ubyte_file: idx3文件路径\n",
    "    :return: 数据集\n",
    "    \"\"\"\n",
    "    # 读取二进制数据\n",
    "    bin_data = open(idx3_ubyte_file, 'rb').read()\n",
    "\n",
    "    # 解析文件头信息，依次为魔数、图片数量、每张图片高、每张图片宽\n",
    "    offset = 0\n",
    "    fmt_header = '>iiii'\n",
    "    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    print('魔数:%d, 图片数量: %d张, 图片大小: %d*%d' % (magic_number, num_images, num_rows, num_cols))\n",
    "\n",
    "    # 解析数据集\n",
    "    image_size = num_rows * num_cols\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>' + str(image_size) + 'B'\n",
    "    images = np.empty((num_images, num_rows, num_cols))\n",
    "    for i in range(num_images):\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print('已解析 %d' % (i + 1) + '张')\n",
    "        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return images\n",
    "\n",
    "\n",
    "def decode_idx1_ubyte(idx1_ubyte_file):\n",
    "    \"\"\"\n",
    "    解析idx1文件的通用函数\n",
    "    :param idx1_ubyte_file: idx1文件路径\n",
    "    :return: 数据集\n",
    "    \"\"\"\n",
    "    # 读取二进制数据\n",
    "    bin_data = open(idx1_ubyte_file, 'rb').read()\n",
    "\n",
    "    # 解析文件头信息，依次为魔数和标签数\n",
    "    offset = 0\n",
    "    fmt_header = '>ii'\n",
    "    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    print('魔数:%d, 图片数量: %d张' % (magic_number, num_images))\n",
    "\n",
    "    # 解析数据集\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>B'\n",
    "    labels = np.empty(num_images)\n",
    "    for i in range(num_images):\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print('已解析 %d' % (i + 1) + '张')\n",
    "        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return labels\n",
    "train_image=decode_idx3_ubyte(train_images_idx3_ubyte_file)\n",
    "test_image=decode_idx3_ubyte(test_images_idx3_ubyte_file)\n",
    "train_label=decode_idx1_ubyte(train_labels_idx1_ubyte_file)\n",
    "test_label=decode_idx1_ubyte(test_labels_idx1_ubyte_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x=train_image[:10,:,:]\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.45108352,  0.97853894,  0.95443716,  0.35144047,  0.60121831,\n",
       "          0.59493628,  0.96680065,  0.45349837],\n",
       "        [ 0.8251878 ,  0.54170803,  0.40032319,  0.09872889,  0.90892739,\n",
       "          0.61790966,  0.39512446,  0.8975492 ],\n",
       "        [ 0.85968283,  0.62822575,  0.86195866,  0.0536954 ,  0.61568534,\n",
       "          0.4025968 ,  0.56970296,  0.44638899],\n",
       "        [ 0.94334667,  0.96442805,  0.33716956,  0.68300729,  0.67116321,\n",
       "          0.3494492 ,  0.96817676,  0.74040573],\n",
       "        [ 0.24893922,  0.99617599,  0.7295618 ,  0.93217924,  0.39241217,\n",
       "          0.9925466 ,  0.84745918,  0.64006337],\n",
       "        [ 0.35425839,  0.85354419,  0.69469609,  0.74143965,  0.29496398,\n",
       "          0.60885071,  0.70437731,  0.40409985],\n",
       "        [ 0.3814682 ,  0.16619566,  0.60456052,  0.30145577,  0.87118812,\n",
       "          0.92347824,  0.03124271,  0.17923938],\n",
       "        [ 0.57187534,  0.48738151,  0.88121143,  0.83210437,  0.5634097 ,\n",
       "          0.84471901,  0.05330581,  0.3129232 ]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=np.random.rand(1,8,8)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.array([0.5])\n",
    "conved_features=cnnConvolve(8, 1, train_x, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21, 1, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conved_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnPool(poolDim, convolvedFeatures,mode=\"max\"):\n",
    "    numImages = convolvedFeatures.shape[3]\n",
    "    numFilters = convolvedFeatures.shape[2]\n",
    "    convolvedDim = convolvedFeatures.shape[1]\n",
    "    print(convolvedDim/poolDim)\n",
    "    pooledFeatures = np.zeros([int(convolvedDim/poolDim),int(convolvedDim/poolDim),numFilters,numImages])\n",
    "    #pooled_dim=(convolvedDim+2*p-f)/s+1\n",
    "    pooled_dim=int(convolvedDim/poolDim)\n",
    "    padding=convolvedDim/poolDim\n",
    "    for imageNum in range(numImages):\n",
    "        for filterNum in range(numFilters):\n",
    "            pooledImage = np.zeros([pooled_dim, pooled_dim]);\n",
    "            for i in range(0,convolvedDim,poolDim):\n",
    "                if i+poolDim>=convolvedDim:\n",
    "                        break\n",
    "                for  j in range(0,convolvedDim,poolDim):\n",
    "                    #print(i,j)\n",
    "                    if j+poolDim>=convolvedDim:\n",
    "                        break\n",
    "                    col=int(i/poolDim)\n",
    "                    row=int(j/poolDim)\n",
    "                    temp_image=convolvedFeatures[i:i+poolDim,j:j+poolDim,filterNum,imageNum]\n",
    "                    if mode=='max':\n",
    "                        pooledImage[col,row]=np.max(temp_image)\n",
    "                    elif mode=='mean':\n",
    "                        pooledImage[col,row]=np.mean(temp_image)\n",
    "            pooledFeatures[:,:,filterNum,imageNum]=pooledImage\n",
    "    return pooledFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "pooledFeatures=cnnPool(7,conved_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooledFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    " \n",
    "    X_pad = np.pad(X, ((0,0),(pad,pad),(pad,pad),(0,0)), 'constant')\n",
    " \n",
    "    return X_pad\n",
    "def conv_backword(dz,cache):\n",
    "    a_input,w,b,hparameters=cache#a表示当前的卷积层的输出，也就是下一个卷积层的输入，dz表示下一个卷积层未经过激活函数处理的值z的梯度导数，w表示卷积核函数\n",
    "    (m,col,row)=a_input.shape#m个样本\n",
    "    (n_c,f,f)=w.shape#n_c个filter\n",
    "    stride=hparameters['stride']\n",
    "    pad=hparameters['pad']\n",
    "    (m,n_h,n_w)=dz.shape\n",
    "    da_input=np.zeros(m,col,row)\n",
    "    dw=np.zeros(n_c,f,f)#n_c个filter\n",
    "    db=np.zeros(n_c,1,1)\n",
    "    for i in range(m):\n",
    "        a_temp=a_input[i,:,:]\n",
    "        da_temp=a_input[i,:,:]\n",
    "        for h in n_h:\n",
    "            for w in n_w:\n",
    "                for c in n_c:\n",
    "                    v_start=h*stride\n",
    "                    v_end=v_start+f\n",
    "                    h_start=w*stride\n",
    "                    h_end=h_start+f\n",
    "                    a_slice=a_temp[v_start:v_end,h_start:h_end]\n",
    "                    da_temp[v_start:v_end,h_start:h_end]+=w[c,:,:]*dz[i,h,w]#对每个z，z都是w矩阵和这个slice卷积得到的，且每个x在不同的slice中会得到不同的z，所以这个slice的每个x的导数都需要加上w矩阵对应的w乘以该slice对应的dz，对输入的每个a在对应slice不同时都会有相应的运算，所以在每次的slice都需要加上对应的导数\n",
    "                    dw[c,:,:]+=a_slice*dz[i,h,w]#对w矩阵中的每个w,在与不同slice卷积时都是与该slice中对应输入a做乘积得到z，所以对每个slice，每个w都需要加上对应输入a与dz的乘积\n",
    "                    db[c,:,:]+=dz[i,h,w]#与dw同理，只不过没有乘输入a\n",
    "        da_input[i,:,:]=da_temp            \n",
    "    return da_input,dw,db\n",
    "def create_mask_frommat(x):\n",
    "    mask=(x==np.max(x))#获得矩阵中只有最大值为1其余都为0\n",
    "    return mask\n",
    "def distribute_value(dz,shape):\n",
    "    (n_h,n_w)=shape\n",
    "    average=dz/(n_h*n_w)\n",
    "    a=average*np.ones(shape)#对矩阵中的每个数都除以矩阵元素总个数，做平均池化的时候就是这么做的\n",
    "    return a\n",
    "def pool_backword(dz,cache,mode):\n",
    "    (a_input,hparamters)=cache\n",
    "    stride=hparameters['stride']\n",
    "    f=hparameters['f']\n",
    "    m,col,row=a_input.shape#m个样本\n",
    "    m,n_h,n_w=dz.shape\n",
    "    da_input=np.zeros(a_input.shape)\n",
    "    for i in range(m):\n",
    "        a_temp=a_input[i,:,:]\n",
    "        for h in range(n_h):\n",
    "            for w in range(n_w):\n",
    "                v_start=h*stride\n",
    "                v_end=v_start+f\n",
    "                h_start=w*stride\n",
    "                h_end=h_start+f\n",
    "                if mode=='max':\n",
    "                    a_slice=a_temp[v_start:v_end,h_start:h_end]\n",
    "                    mask=create_mask_frommat(a_slice)\n",
    "                    da_input[i,:,:]+=mask*dz[i,h,w]#每次slice中只有最大的那一个最后被纳入z中，所以只需要最大的那个乘以dz，其余的都不需要\n",
    "                elif mode=='average':\n",
    "                    dz_temp=dz[i,:,:]\n",
    "                    shape=(f,f)\n",
    "                    a_slice=a_temp[v_start:v_end,h_start:h_end]\n",
    "                    da_input[i,:,:]+=distribute_value(dz_temp,shape)#每次的slice都是将每个输入a乘上1/f*f然后加总得到z，所以每个输入a的导数都需要加上1、f*f乘以对应slice的dz\n",
    "    return da_input     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
